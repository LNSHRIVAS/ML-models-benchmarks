{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4XS3TBuOK2J",
        "outputId": "fe87e74d-0899-487a-f9d2-eb2f10659e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "391/391 - 256s - 655ms/step - accuracy: 0.7277 - loss: 0.5386\n",
            "Epoch 2/3\n",
            "391/391 - 263s - 674ms/step - accuracy: 0.8840 - loss: 0.2840\n",
            "Epoch 3/3\n",
            "391/391 - 261s - 666ms/step - accuracy: 0.9270 - loss: 0.1941\n",
            "[CPU] Time: 789.35s | Accuracy: 0.8736\n",
            "No GPU available.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import time\n",
        "\n",
        "# Settings\n",
        "max_features = 10000  # Vocabulary size\n",
        "maxlen = 500          # Max sequence length\n",
        "batch_size = 64\n",
        "epochs = 3\n",
        "\n",
        "# Load IMDB data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define LSTM model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Embedding(max_features, 128),\n",
        "        LSTM(64),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Select device\n",
        "def train_on_device(device_name):\n",
        "    with tf.device(device_name):\n",
        "        model = build_model()\n",
        "        start = time.time()\n",
        "        model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "        train_time = time.time() - start\n",
        "        loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        return train_time, acc\n",
        "\n",
        "# CPU benchmarking\n",
        "cpu_time, cpu_acc = train_on_device(\"/CPU:0\")\n",
        "print(f\"[CPU] Time: {cpu_time:.2f}s | Accuracy: {cpu_acc:.4f}\")\n",
        "\n",
        "# GPU benchmarking (if available)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    gpu_time, gpu_acc = train_on_device(\"/GPU:0\")\n",
        "    print(f\"[GPU] Time: {gpu_time:.2f}s | Accuracy: {gpu_acc:.4f}\")\n",
        "else:\n",
        "    print(\"No GPU available.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUYSlSVtR4j4",
        "outputId": "65045d50-3a8e-44b2-e2f4-62606f2170ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "391/391 - 12s - 31ms/step - accuracy: 0.7853 - loss: 0.4529\n",
            "Epoch 2/3\n",
            "391/391 - 18s - 46ms/step - accuracy: 0.8861 - loss: 0.2844\n",
            "Epoch 3/3\n",
            "391/391 - 10s - 26ms/step - accuracy: 0.9172 - loss: 0.2132\n",
            "[GPU] Time: 42.76s | Accuracy: 0.8613\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import time\n",
        "\n",
        "# Settings\n",
        "max_features = 10000  # Vocabulary size\n",
        "maxlen = 500          # Max sequence length\n",
        "batch_size = 64\n",
        "epochs = 3\n",
        "\n",
        "# Load IMDB data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define LSTM model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Embedding(max_features, 128),\n",
        "        LSTM(64),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Select device\n",
        "def train_on_device(device_name):\n",
        "    with tf.device(device_name):\n",
        "        model = build_model()\n",
        "        start = time.time()\n",
        "        model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "        train_time = time.time() - start\n",
        "        loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        return train_time, acc\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    gpu_time, gpu_acc = train_on_device(\"/GPU:0\")\n",
        "    print(f\"[GPU] Time: {gpu_time:.2f}s | Accuracy: {gpu_acc:.4f}\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ajE18ESWQG",
        "outputId": "831728f1-394a-4d2d-e496-f7cd073eed3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "196/196 - 7s - 35ms/step - accuracy: 0.7912 - loss: 0.4365\n",
            "Epoch 2/3\n",
            "196/196 - 6s - 28ms/step - accuracy: 0.8847 - loss: 0.2868\n",
            "Epoch 3/3\n",
            "196/196 - 10s - 51ms/step - accuracy: 0.9221 - loss: 0.2072\n",
            "[GPU] Time: 27.58s | Accuracy: 0.8540\n"
          ]
        }
      ],
      "source": [
        "# Settings\n",
        "max_features = 10000  # Vocabulary size\n",
        "maxlen = 500          # Max sequence length\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "\n",
        "# Load IMDB data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define LSTM model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Embedding(max_features, 256),\n",
        "        LSTM(64),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Select device\n",
        "def train_on_device(device_name):\n",
        "    with tf.device(device_name):\n",
        "        model = build_model()\n",
        "        start = time.time()\n",
        "        model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "        train_time = time.time() - start\n",
        "        loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        return train_time, acc\n",
        "\n",
        "\n",
        "\n",
        "# HERE WE are running the configuration on GPU with batch size as 128. This resulted in faster training time on the GPU when\n",
        "    # compared with a batch size of 64\n",
        "\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    gpu_time, gpu_acc = train_on_device(\"/GPU:0\")\n",
        "    print(f\"[GPU] Time: {gpu_time:.2f}s | Accuracy: {gpu_acc:.4f}\")\n",
        "else:\n",
        "    print(\"No GPU available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu5bYHFGT9uU",
        "outputId": "2bcb8571-27ab-4a61-c10d-1b2263897ea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "196/196 - 13s - 64ms/step - accuracy: 0.7414 - loss: 0.4963\n",
            "Epoch 2/3\n",
            "196/196 - 21s - 105ms/step - accuracy: 0.8876 - loss: 0.2778\n",
            "Epoch 3/3\n",
            "196/196 - 20s - 104ms/step - accuracy: 0.9193 - loss: 0.2120\n",
            "[CPU] Training Time: 63.18s | Inference Time: 5.40s | Accuracy: 0.8782\n",
            "Epoch 1/3\n",
            "196/196 - 6s - 30ms/step - accuracy: 0.7899 - loss: 0.4414\n",
            "Epoch 2/3\n",
            "196/196 - 4s - 22ms/step - accuracy: 0.8998 - loss: 0.2579\n",
            "Epoch 3/3\n",
            "196/196 - 4s - 23ms/step - accuracy: 0.9282 - loss: 0.1941\n",
            "[GPU] Training Time: 14.62s | Inference Time: 2.16s | Accuracy: 0.8748\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# here we reduced the number of features to 128, which resulted in faster training time and even yielded higher accuracy.\n",
        "\n",
        "# Settings\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size =  128\n",
        "epochs = 3\n",
        "\n",
        "# Load IMDB data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define LSTM model\n",
        "def build_model():\n",
        "    model = Sequential([\n",
        "        Embedding(max_features, 128),\n",
        "        LSTM(64),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Training and inference on specified device\n",
        "def benchmark_on_device(device_name):\n",
        "    with tf.device(device_name):\n",
        "        model = build_model()\n",
        "\n",
        "        # Training\n",
        "        start_train = time.time()\n",
        "        model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
        "        train_time = time.time() - start_train\n",
        "\n",
        "        # Inference\n",
        "        start_infer = time.time()\n",
        "        loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
        "        infer_time = time.time() - start_infer\n",
        "\n",
        "        return train_time, infer_time, acc\n",
        "\n",
        "# Run CPU benchmark\n",
        "cpu_train_time, cpu_infer_time, cpu_acc = benchmark_on_device(\"/CPU:0\")\n",
        "print(f\"[CPU] Training Time: {cpu_train_time:.2f}s | Inference Time: {cpu_infer_time:.2f}s | Accuracy: {cpu_acc:.4f}\")\n",
        "\n",
        "# Run GPU benchmark (if available)\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    gpu_train_time, gpu_infer_time, gpu_acc = benchmark_on_device(\"/GPU:0\")\n",
        "    print(f\"[GPU] Training Time: {gpu_train_time:.2f}s | Inference Time: {gpu_infer_time:.2f}s | Accuracy: {gpu_acc:.4f}\")\n",
        "else:\n",
        "    print(\"GPU not available.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
